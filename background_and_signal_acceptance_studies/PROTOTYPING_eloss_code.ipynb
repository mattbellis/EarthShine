{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fde00-b707-4157-b25d-25698ff88e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from skspatial.objects import Line, Plane\n",
    "from skspatial.plotting import plot_3d\n",
    "\n",
    "\n",
    "from skspatial.objects import Line, Cylinder, Point, Points\n",
    "from skspatial.plotting import plot_3d\n",
    "\n",
    "import phasespace\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import bisect\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.integrate import quad, trapezoid\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import stats\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import matplotlib\n",
    "\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import scipy\n",
    "\n",
    "from scipy import integrate \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import dm_generation_tools as dgt\n",
    "import detector_simulation_tools as dst\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "####################################\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe099ed-227e-4cc9-8403-1e9d69338f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.__version__ = }')\n",
    "print(f'{matplotlib.__version__ = }')\n",
    "print(f'{pd.__version__ = }')\n",
    "print(f'{scipy.__version__ = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d927a3-1ec0-4418-bf95-6f1de3038ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need this file. Make sure there is a soft link to it\n",
    "infilename_for_eloss = 'muons_summary_from_GEANT4_simulations.parquet'\n",
    "df_eloss = pd.read_parquet(infilename_for_eloss)\n",
    "df_eloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d112b-9098-40e0-a84f-fe785188161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots\n",
    "e_initials = df_eloss['e_initial'].unique()\n",
    "e_initials\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "for idx,ei in enumerate(e_initials[0:2]):\n",
    "    print(f\"ei: {ei}\")\n",
    "    filter = df_eloss['e_initial']==ei\n",
    "\n",
    "    z = df_eloss[filter]['z']\n",
    "    ef = ei - df_eloss[filter]['e']\n",
    "\n",
    "    print(len(z))\n",
    "    print(len(ef))\n",
    "\n",
    "    plt.subplot(1,2,idx+1)\n",
    "    plt.plot(z,ef,'.',markersize=0.1)\n",
    "    plt.xlabel('z (m)')\n",
    "    plt.ylabel('Final energy (GeV)')\n",
    "    plt.title(f'Initial energy: {ei} GeV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394377a-d2a7-4fc5-a141-03aa0b418c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(sorted_list, x):\n",
    "    \"\"\"\n",
    "    Given sorted_list (ascending) and a value x,\n",
    "    return (low, high) where:\n",
    "      - low  = the largest element <= x (or None if x < sorted_list[0])\n",
    "      - high = the smallest element >= x (or None if x > sorted_list[-1])\n",
    "    \"\"\"\n",
    "    idx = bisect.bisect_left(sorted_list, x)\n",
    "    # idx is the insertion point to keep the list sorted.\n",
    "    if idx == 0:\n",
    "        # x is <= first element\n",
    "        return None, sorted_list[0]\n",
    "    elif idx == len(sorted_list):\n",
    "        # x is greater than all elements\n",
    "        return sorted_list[-1], None\n",
    "    else:\n",
    "        # sorted_list[idx-1] < x <= sorted_list[idx]\n",
    "        return sorted_list[idx-1], sorted_list[idx]\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "def energy_after_traveling_distance(e_initials, zvals, eivals, efvals, E_muon, distance, make_plots=False, ngendata=1, verbose=False):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # My own \n",
    "    d = distance\n",
    "    dwidth = 0.01 * d\n",
    "\n",
    "    #print(e_initials)\n",
    "    #E_muon = 45040\n",
    "    elo,ehi = find_neighbors(e_initials, E_muon)\n",
    "    delta_e = ehi - elo\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"In function: time to run A: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "    #print(elo, ehi, delta_e)\n",
    "    \n",
    "    frequencies = []\n",
    "    eis = []\n",
    "    efs = []\n",
    "    \n",
    "    #plt.figure(figsize=(16,8))\n",
    "    \n",
    "    # First find the ranges\n",
    "    elo_min = [1e99, 1e99]\n",
    "    ehi_max = [-1e99, -1e99]\n",
    "    \n",
    "    #filter_distance = (zvals > d-dwidth) & (zvals < d+dwidth)\n",
    "    \n",
    "    for i,Ei in enumerate([elo,ehi]):\n",
    "        \n",
    "        filter = (eivals==Ei)# & filter_distance\n",
    "        #filter = filter & \n",
    "        \n",
    "        #vals = Ei - efvals[filter]\n",
    "        vals = efvals[filter]\n",
    "    \n",
    "        if len(vals) < 10:\n",
    "            if verbose:\n",
    "                print(\"NO DATA TO WORK WITH\")\n",
    "            return -1*np.ones(ngendata,dtype=int)\n",
    "            #continue\n",
    "            \n",
    "        test_min = min(vals)\n",
    "        test_max = max(vals)\n",
    "        if test_min <= elo_min[i]:\n",
    "            elo_min[i] = test_min\n",
    "        if test_max >= ehi_max[i]:\n",
    "            ehi_max[i] = test_max\n",
    "    if verbose:\n",
    "        print(f\"In function: time to run B: {time.time() - start:.2f} seconds\")\n",
    "    \n",
    "    for i,Ei in enumerate([elo,ehi]):\n",
    "        #Ei = 30000\n",
    "        \n",
    "        filter = (eivals==Ei)# & filter_distance\n",
    "        #filter = filter & (zvals > d-dwidth) & (zvals < d+dwidth)\n",
    "        \n",
    "        #vals = Ei - efvals[filter]\n",
    "        vals = efvals[filter]\n",
    "\n",
    "        if make_plots:\n",
    "            plt.subplot(2,2,1)\n",
    "            plt.hist(vals, bins=100, range=(elo_min[i], ehi_max[i]),label=f'{Ei}', alpha=0.5);\n",
    "            plt.legend()\n",
    "\n",
    "        if len(vals) < 10:\n",
    "            if verbose:\n",
    "                print(\"NO DATA TO WORK WITH\")\n",
    "            return -1*np.ones(ngendata,dtype=int)\n",
    "            #continue\n",
    "\n",
    "        kde = stats.gaussian_kde(vals)\n",
    "        xpts = np.linspace(elo_min[i], ehi_max[i], 100)\n",
    "        ypts = kde(xpts)\n",
    "        #frequencies = kde.evaluate(xpts)\n",
    "    \n",
    "        # Shift up the lower one\n",
    "        #if i==0:\n",
    "        #    xpts += delta_e\n",
    "    \n",
    "        # Normalize the xpts\n",
    "        e_range = ehi_max[i] - elo_min[i]\n",
    "        xpts -= elo_min[i]\n",
    "        xpts /= e_range\n",
    "\n",
    "        if make_plots:\n",
    "            plt.subplot(2,2,2)\n",
    "            plt.plot(xpts,ypts, label=f'{Ei}')\n",
    "            #plt.xlim(0,1.1*ehi)\n",
    "            plt.legend()\n",
    "    \n",
    "        efs += xpts.tolist()\n",
    "        eis += (Ei * np.ones_like(xpts)).tolist()\n",
    "        frequencies += ypts.tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"In function: time to run C: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "    data = np.array([eis, efs])\n",
    "    #print(data.shape, len(frequencies))\n",
    "    interp = LinearNDInterpolator(data.T, frequencies )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"In function: time to run D: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "    #xpts_temp = np.linspace(elo_min,ehi_max,100)\n",
    "    xpts_temp = np.linspace(0,1,100)\n",
    "    \n",
    "    ypts_temp = interp(E_muon,xpts_temp);\n",
    "    \n",
    "    filter = ypts_temp==ypts_temp\n",
    "    \n",
    "    # Cut out the nans since some of the points are out of range\n",
    "    xpts = xpts_temp[filter]\n",
    "    ypts = ypts_temp[filter]\n",
    "    \n",
    "    # Shift the xpoints down\n",
    "    #xpts -= (ehi - E_muon)\n",
    "\n",
    "    if make_plots:\n",
    "        #plt.figure()\n",
    "        plt.plot(xpts,ypts, label=f'{E_muon}')\n",
    "        plt.legend()\n",
    "    \n",
    "    # Sample points\n",
    "    dx = xpts[1] - xpts[0]\n",
    "    #print(dx)\n",
    "    #print(ypts)\n",
    "    \n",
    "    cdf = np.cumsum(ypts)*dx\n",
    "    #print(cdf)\n",
    "    \n",
    "    cdf /= cdf[-1]\n",
    "    \n",
    "    #print(cdf)\n",
    "    if verbose:\n",
    "        print(f\"In function: time to run E: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "    if make_plots:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(xpts, cdf, label='CDF')\n",
    "        #print(cdf)\n",
    "        plt.legend()\n",
    "    \n",
    "    #filter = (xpts>=elo_min) & (xpts<=ehi_max)\n",
    "    #print(cdf)\n",
    "    #print(cdf[filter])\n",
    "    \n",
    "    spl = CubicSpline(xpts, cdf)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"In function: time to run F: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "    gendata = []\n",
    "    #ngendata = 5000\n",
    "    nfail = 0\n",
    "    \n",
    "    # Scaling\n",
    "    frac_of_diff = (E_muon - elo) / (ehi - elo)\n",
    "    #print(f\"{frac_of_diff = }\")\n",
    "    e_range_0 = ehi_max[0] - elo_min[0]\n",
    "    e_range_1 = ehi_max[1] - elo_min[1]\n",
    "    #print(f\"{e_range_0 = }\")\n",
    "    #print(f\"{e_range_1 = }\")\n",
    "    \n",
    "    e_muon_range = e_range_0 + ((e_range_1 - e_range_0)*frac_of_diff)\n",
    "    e_muon_lo   = elo_min[0] + ((elo_min[1] - elo_min[0])*frac_of_diff)\n",
    "    #print(f\"{e_muon_range = }\")\n",
    "    #print(f\"{e_muon_lo = }\")\n",
    "    \n",
    "    #ngendata = 1\n",
    "    icount = 0\n",
    "    \n",
    "    while icount < ngendata:\n",
    "        #print(icount, ngendata)\n",
    "        u = np.random.random() # Generates a float between 0.0 and 1.0\n",
    "    \n",
    "        #print(f\"In function: time to run G - a: {time.time() - start:.2f} seconds\")\n",
    "\n",
    "        ynew = spl.solve(u)\n",
    "        #print(f\"In function: time to run G - b: {time.time() - start:.2f} seconds\")\n",
    "        \n",
    "        #xnew = max(ynew)\n",
    "        #filter = (ynew>0) & (ynew<ehi_max)\n",
    "        filter = (ynew>0) & (ynew<1)\n",
    "    \n",
    "        xnew = ynew[filter]\n",
    "        if len(xnew) == 1:\n",
    "            good_val = xnew[0]\n",
    "            good_val *= e_muon_range\n",
    "            good_val += e_muon_lo\n",
    "        else:\n",
    "            print(u, ynew, xnew)\n",
    "            nfail += 1\n",
    "            continue\n",
    "        #print(good_val)\n",
    "        #plt.subplot(1,3,2)\n",
    "        #print(xnew,u)\n",
    "        #plt.plot(xnew, u, 'ro', markersize=5)\n",
    "        \n",
    "        gendata.append(good_val)\n",
    "        icount += 1\n",
    "\n",
    "    if make_plots:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.hist(gendata, bins=200)#, range=(0,1));\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"In function: time to run G: {time.time() - start:.2f} seconds\")\n",
    "        print(f'{nfail = }')\n",
    "\n",
    "    return gendata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a41dfc-a66b-4050-81b5-8333b93f57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the energy loss code\n",
    "e_initials = df_eloss['e_initial'].unique()\n",
    "zvals = df_eloss['z'].values\n",
    "eivals = df_eloss['e_initial']\n",
    "efvals = df_eloss['e']\n",
    "    \n",
    "start = time.time()\n",
    "distance = 1000\n",
    "distance_width = 0.01 * distance\n",
    "E_muon = 45000\n",
    "\n",
    "elo,ehi = find_neighbors(e_initials, E_muon)\n",
    "filter = (eivals==elo) | (eivals==ehi)\n",
    "filter = filter & (zvals>distance - distance_width) & (zvals<distance+distance_width)\n",
    "\n",
    "print(\"Here\")\n",
    "\n",
    "delta_e = energy_after_traveling_distance(e_initials, zvals[filter], eivals[filter], efvals[filter], E_muon=E_muon, distance=distance, make_plots=False, ngendata=1)\n",
    "print(f\"Time to run: {time.time() - start:.2f} seconds\")\n",
    "de = delta_e[0]\n",
    "e_final = E_muon - de\n",
    "print(f\"{E_muon:.2f}  {de:.2f}   {e_final:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f68184-8d7f-4ad2-a18e-e41c7be3f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots\n",
    "e_initials = df_eloss['e_initial'].unique()\n",
    "e_initials\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "for idx,ei in enumerate(e_initials[0:2]):\n",
    "    print(f\"ei: {ei}\")\n",
    "    filter = df_eloss['e_initial']==ei\n",
    "\n",
    "    z = df_eloss[filter]['z']\n",
    "    ef = ei - df_eloss[filter]['e']\n",
    "\n",
    "    print(len(z))\n",
    "    print(len(ef))\n",
    "\n",
    "    plt.subplot(1,2,idx+1)\n",
    "    plt.plot(z,ef,'.',markersize=0.1)\n",
    "    plt.xlabel('z (m)')\n",
    "    plt.ylabel('Final energy (GeV)')\n",
    "    plt.title(f'Initial energy: {ei} GeV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a913038-f0c5-4120-a903-b65c6babca90",
   "metadata": {},
   "source": [
    "# Find max distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9fd70-9ea2-4536-a8ac-75948b339576",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials = df_eloss['e_initial'].unique()\n",
    "\n",
    "print(len(e_initials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28356ff-1692-4ad2-8034-78620d622143",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eloss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac7285-1d4c-400d-b407-51a1a0f718f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials = df_eloss['e_initial'].unique()\n",
    "eivals = df_eloss['e_initial']\n",
    "\n",
    "dict_max_distances = {'e_initial':[], 'max_distance':[]}\n",
    "\n",
    "for e_initial in e_initials:\n",
    "    filter = (eivals==e_initial)\n",
    "\n",
    "    distances = df_eloss[filter]['z']\n",
    "    #print(e_initial, max(distances))\n",
    "    \n",
    "    dict_max_distances['e_initial'].append(e_initial)\n",
    "    dict_max_distances['max_distance'].append(max(distances))\n",
    "\n",
    "df_md = pd.DataFrame.from_dict(dict_max_distances)\n",
    "\n",
    "df_md\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb30bb-2bde-4c01-a2cb-fa24fda7444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df_md, x='e_initial', y='max_distance')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2d1a5-1d3b-4783-8718-fab1747f9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials = df_eloss['e_initial'].unique()\n",
    "eivals = df_eloss['e_initial']\n",
    "distances = df_eloss['z']\n",
    "\n",
    "dict_max_distances = {'e_initial':[], 'max_distance':[]}\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "for idx,e_initial in enumerate(e_initials):\n",
    "    print(e_initial)\n",
    "    filter = (eivals==e_initial)\n",
    "\n",
    "    plt.subplot(7,4,idx+1)\n",
    "    plt.hist(distances[filter],bins=100,label=f'$E_i$ = {e_initial}')\n",
    "    plt.legend()\n",
    "    plt.yscale('log')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751a27a-a8f6-42bc-a836-5266f69d48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a09bc7-c23b-4299-8bbc-9fca080bf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eloss.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fa90d9-78ee-44d7-941e-61aed64f63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eloss['e_initial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285dc82e-2048-4b2b-b209-e12251f946d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_de(df_eloss, E_muon, distance, dwidth=10, bandwidth = 0.1):\n",
    "\n",
    "    e_initials = df_eloss['e_initial']\n",
    "    distances = df_eloss['z']\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "\n",
    "    filter = (e_initials==E_muon)\n",
    "    filter = filter & (distances < (distance+dwidth)) & (distances>(distance-dwidth))\n",
    "\n",
    "    vals = df_eloss[filter]['e']\n",
    "    if len(vals)==0:\n",
    "        return 0\n",
    "\n",
    "    print(len(vals))\n",
    "    \n",
    "    kde1 = gaussian_kde(vals, bw_method=bandwidth)\n",
    "    xpts = np.linspace(min(vals), max(vals), 500)\n",
    "\n",
    "\n",
    "    plt.hist(vals,bins=50, density=True)\n",
    "    plt.plot(xpts, kde1(xpts))\n",
    "    #plt.legend()\n",
    "    #plt.yscale('log')\n",
    "    plt.xlim(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077388e-48f6-4e8a-a318-7164e7a3d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_de(df_eloss, 80000, 5300, dwidth=100, bandwidth=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fc49c-1d32-4797-92fc-33c6420224ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_de_for_energy(df_eloss, E_muon, bandwidth = 0.1):\n",
    "\n",
    "    e_initials = df_eloss['e_initial']\n",
    "\n",
    "    filter = (e_initials==E_muon)\n",
    "    \n",
    "    distances = df_eloss[filter]['z']\n",
    "    de = df_eloss[filter]['e']\n",
    "\n",
    "    lo,hi = min(de),max(de)\n",
    "    dwidth = (hi-lo)/100\n",
    "\n",
    "    print(f'Total: {len(de)}   lo/hi: {lo} {hi}    dist width: {dwidth}')\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    output = \"\"\n",
    "    for idx in range(0,100):\n",
    "    \n",
    "        distance_lo = lo + (idx*dwidth)\n",
    "        distance_hi = lo + ((idx+1)*dwidth)\n",
    "\n",
    "        filter_dist = (distances > distance_lo) & (distances<distance_hi)\n",
    "\n",
    "        vals = de[filter_dist]\n",
    "\n",
    "        if len(vals)<50:\n",
    "            continue\n",
    "\n",
    "        output += f\"{len(vals):6d} \"\n",
    "        if (idx+1)%10==0:\n",
    "            print(output)\n",
    "            output = \"\"\n",
    "    \n",
    "        kde1 = gaussian_kde(vals, bw_method=bandwidth)\n",
    "        xpts = np.linspace(min(vals), max(vals), 500)\n",
    "        \n",
    "        plt.subplot(10,10,idx+1)\n",
    "        plt.hist(vals,bins=50, density=True)\n",
    "        plt.plot(xpts, kde1(xpts))\n",
    "        #plt.legend()\n",
    "        #plt.yscale('log')\n",
    "        plt.xlim(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41419919-1a8c-4754-8868-1b567721fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_de_for_energy(df_eloss, E_muon=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf1c95-8a98-4c68-b44b-4ee5daf030ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab595f16-092a-473c-a940-202b71cd6f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c804d-b292-4e47-9730-74d0cba94448",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_neighbors(e_initials, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402fd308-9cbe-478b-83bf-d15a527f9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials = df_eloss['e_initial']\n",
    "z_vals = df_eloss['z']\n",
    "ef_vals = df_eloss['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbab76-52e5-48d7-a1d3-4db67903e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.neighbors import KernelDensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af324b-4924-4da0-bbce-6b12d7d501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials_unique = df_eloss['e_initial'].unique()\n",
    "\n",
    "\n",
    "data = {'e_i':[], 'dist':[], 'de_min':[], 'de_max':[]}\n",
    "\n",
    "for d in [50, 75, 100, 200, 500, 1000]:\n",
    "    #d = 75 # meters\n",
    "    dwidth = 0.05 * d\n",
    "    print(d,dwidth)\n",
    "    \n",
    "    for e_i in e_initials_unique:\n",
    "    \n",
    "        #############################################\n",
    "        \n",
    "        filter_e1 = (e_initials==e_i)\n",
    "        filter_d1 = (z_vals>=d-dwidth) & (z_vals<=d+dwidth)\n",
    "        \n",
    "        de1 = df_eloss[filter_e1 & filter_d1]['e']\n",
    "\n",
    "        de_min = 0\n",
    "        de_max = 0\n",
    "        if len(de1)>0:\n",
    "            de_min = min(de1)\n",
    "        if len(de1)>0:\n",
    "            de_max = max(de1)\n",
    "    \n",
    "        #print(e_i, de_min, de_max)\n",
    "    \n",
    "        data['e_i'].append(e_i)\n",
    "        data['de_min'].append(de_min)\n",
    "        data['de_max'].append(de_max)\n",
    "        data['dist'].append(d)\n",
    "    \n",
    "df_min_max = pd.DataFrame.from_dict(data)\n",
    "\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b7c54-87e2-48c8-9cf0-394756fce330",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize=(12,5))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "sns.scatterplot(data=df_min_max, x='e_i', y='de_min', hue='dist')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "plt.sca(axes[1])\n",
    "sns.scatterplot(data=df_min_max, x='e_i', y='de_max', hue='dist')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1083d5-3c3e-461e-9778-2ba0691e96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_de_ranges(de1, de2):\n",
    "    elo_vals = np.array([min(de1), min(de2)])\n",
    "    ehi_vals = np.array([max(de1), max(de2)])\n",
    "\n",
    "    \n",
    "    elo_min = min(elo_vals)\n",
    "    ehi_max = max(ehi_vals)\n",
    "\n",
    "    #print(elo_min, ehi_max)\n",
    "\n",
    "    return elo_vals, ehi_vals, elo_min, ehi_max\n",
    "################################################################\n",
    "\n",
    "\n",
    "\n",
    "def get_data_and_kde_for_interpolation(E_muon=100, distance=50, df_eloss=None, e_initials_unique=None, dwidth_pct=0.05):\n",
    "\n",
    "    if E_muon <= min(e_initials_unique):\n",
    "        print(\"E_muon is too low\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    dwidth = 0.05 * distance\n",
    "    #print(d,dwidth)\n",
    "\n",
    "    elo,ehi = find_neighbors(e_initials_unique, E_muon)\n",
    "    print(E_muon, elo, ehi)\n",
    "\n",
    "    filter_e1 = (e_initials==elo)\n",
    "    filter_e2 = (e_initials==ehi)\n",
    "    filter_d1 = (z_vals>=distance-dwidth) & (z_vals<=distance+dwidth)\n",
    "    \n",
    "    de1 = df_eloss[filter_e1 & filter_d1]['e']\n",
    "    de2 = df_eloss[filter_e2 & filter_d1]['e']\n",
    "\n",
    "    #print(de1)\n",
    "    #####################################\n",
    "    \n",
    "    bandwidth = 0.1\n",
    "    kde1 = gaussian_kde(de1, bw_method=bandwidth)\n",
    "    kde2 = gaussian_kde(de2, bw_method=bandwidth)\n",
    "\n",
    "    elo_vals, ehi_vals, elo_min,ehi_max = find_de_ranges(de1, de2)\n",
    "    \n",
    "    xpts = np.linspace(elo_min,ehi_max,500)\n",
    "\n",
    "\n",
    "    return de1, de2, kde1, kde2, xpts, elo, ehi\n",
    "\n",
    "######################################################################\n",
    "def morph_distributions(E_muon, kde1, kde2, xpts, elo, ehi):\n",
    "\n",
    "    kde1_norm_vals = kde1.pdf(xpts)\n",
    "    kde2_norm_vals = kde2.pdf(xpts)\n",
    "\n",
    "    kde1_integral = integrate.trapezoid(kde1_norm_vals, xpts)\n",
    "    kde2_integral = integrate.trapezoid(kde2_norm_vals, xpts)\n",
    "    \n",
    "    #print(kde1_integral, kde2_integral)\n",
    "    \n",
    "    kde1_norm_vals /= kde1_integral\n",
    "    kde2_norm_vals /= kde2_integral\n",
    "    \n",
    "    scale_factor = (ehi - E_muon)/(ehi-elo)\n",
    "    #print(f'{E_muon=}   {elo=}  {ehi=}  {scale_factor=}')\n",
    "    kde3_norm_vals =  (scale_factor*kde1_norm_vals) + ((1-scale_factor)*kde2_norm_vals)\n",
    "\n",
    "    # Cut out values that are greater than the initial energy of the muon\n",
    "    filter = xpts>E_muon\n",
    "    kde3_norm_vals[filter] = 0\n",
    "    \n",
    "    kde3_norm_integral = integrate.trapezoid(kde3_norm_vals, xpts)\n",
    "    kde3_norm_vals /= kde3_norm_integral\n",
    "\n",
    "    return kde1_norm_vals, kde2_norm_vals, kde3_norm_vals\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "def generate_cdf_and_spline(xpts, ypts):\n",
    "\n",
    "    # Sample points\n",
    "    dx = xpts[1] - xpts[0]\n",
    "    #print(dx)\n",
    "    #print(ypts)\n",
    "    \n",
    "    cdf = np.cumsum(ypts)*dx\n",
    "    #print(cdf)\n",
    "    \n",
    "    cdf /= cdf[-1]\n",
    "\n",
    "    spl = CubicSpline(xpts, cdf)\n",
    "\n",
    "    return cdf, spl\n",
    "\n",
    "############################################################\n",
    "\n",
    "def generate_data_from_spline(spl, npts):\n",
    "\n",
    "    #print(\"Generating random points..........\")\n",
    "\n",
    "    min_val,max_val = spl.x[0],spl.x[-1]\n",
    "    \n",
    "    start = time.time()\n",
    "    #npts = 5000\n",
    "    values = []\n",
    "    values_random_numbers = np.random.random(npts)\n",
    "    \n",
    "    for i in range(npts):\n",
    "        \n",
    "        solutions = spl.solve(values_random_numbers[i])\n",
    "        filter = (solutions>=min_val) & (solutions<=max_val)\n",
    "        solutions = solutions[filter]\n",
    "        \n",
    "        if len(solutions)==1:\n",
    "            #ynew=ynew[0]\n",
    "            #print(ynew)\n",
    "            values.append(solutions[0])\n",
    "    \n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b552d2-ff18-42d9-a5e6-325f634aca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spl.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059363c-6f88-4ca7-a1e0-6119bae0e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_muon = 1600\n",
    "distance = 500\n",
    "e_initials_unique = df_eloss['e_initial'].unique()\n",
    "\n",
    "\n",
    "de1, de2, kde1, kde2, xpts, elo, ehi = get_data_and_kde_for_interpolation(E_muon=E_muon, distance=distance, df_eloss=df_eloss, e_initials_unique=e_initials_unique, dwidth_pct=0.05)\n",
    "\n",
    "kde1_norm_vals, kde2_norm_vals, kde3_norm_vals = morph_distributions(E_muon, kde1, kde2, xpts, elo, ehi)\n",
    "\n",
    "cdf1, spl1 = generate_cdf_and_spline(xpts, kde1_norm_vals)\n",
    "cdf2, spl2 = generate_cdf_and_spline(xpts, kde2_norm_vals)\n",
    "cdf3, spl3 = generate_cdf_and_spline(xpts, kde3_norm_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba7ac1f-b5fe-4781-9eb9-bdd9adabd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(3,1,figsize=(12,12))\n",
    "axes[0].plot(xpts, cdf1, lw=2, label=f'{elo}')\n",
    "axes[0].plot(xpts, cdf2, lw=2,label=f'{ehi}')\n",
    "axes[0].plot(xpts,  cdf3, lw=2, label=f'{E_muon}')\n",
    "axes[0].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0970c3-a665-4b71-8159-0401cfc50c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_initials_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c3862-16aa-4bc2-9f78-cc77add50702",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "ax = plt.figure(figsize=(8,8)).add_subplot(projection='3d')\n",
    "\n",
    "E_muons = []\n",
    "for i in range(0,10):\n",
    "    \n",
    "    E_muon = 10000 + 1000*i\n",
    "    distance = 400\n",
    "\n",
    "    E_muons.append(E_muon)\n",
    "    \n",
    "    de1, de2, kde1, kde2, xpts, elo, ehi = get_data_and_kde_for_interpolation(E_muon=E_muon, distance=distance, df_eloss=df_eloss, e_initials_unique=e_initials_unique, dwidth_pct=0.05)\n",
    "    \n",
    "    kde1_norm_vals, kde2_norm_vals, kde3_norm_vals = morph_distributions(E_muon, kde1, kde2, xpts, elo, ehi)\n",
    "    \n",
    "    y = E_muon\n",
    "    z = kde3_norm_vals\n",
    "\n",
    "    ax.fill_between(xpts, y, z,\n",
    "                    xpts, y, 0,\n",
    "                    #facecolors='r', \n",
    "                    alpha=.7)\n",
    "\n",
    "    ax.set_xlabel(r'$\\Delta E$ (GeV)')\n",
    "    ax.set_ylabel(r'Initial $E_{\\mu}$ (GeV)')\n",
    "\n",
    "\n",
    "ax.set_title(f'Energy loss after {distance} meters')\n",
    "####################################################\n",
    "\n",
    "filename = f'energy_loss_for_muons_with_energy_{int(E_muons[0])}-{int(E_muons[-1])}_after_traveling_{distance}_meters.png'\n",
    "plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdb463-bd8b-4fc0-a507-d5b992e8571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_muon = 1600\n",
    "distance = 500\n",
    "e_initials_unique = df_eloss['e_initial'].unique()\n",
    "\n",
    "\n",
    "de1, de2, kde1, kde2, xpts, elo, ehi = get_data_and_kde_for_interpolation(E_muon=E_muon, distance=distance, df_eloss=df_eloss, e_initials_unique=e_initials_unique, dwidth_pct=0.05)\n",
    "\n",
    "kde1_norm_vals, kde2_norm_vals, kde3_norm_vals = morph_distributions(E_muon, kde1, kde2, xpts, elo, ehi)\n",
    "\n",
    "cdf1, spl1 = generate_cdf_and_spline(xpts, kde1_norm_vals)\n",
    "cdf2, spl2 = generate_cdf_and_spline(xpts, kde2_norm_vals)\n",
    "cdf3, spl3 = generate_cdf_and_spline(xpts, kde3_norm_vals)\n",
    "\n",
    "\n",
    "npts = 500\n",
    "\n",
    "start = time.time()\n",
    "vals = generate_data_from_spline(spl3, npts)\n",
    "print(f\"It took {time.time()-start} seconds to generate {npts} events\")\n",
    "\n",
    "plt.hist(vals,bins=50)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5223abc-3eab-4d31-b982-e7a4c5bf01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 5000\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "E_muons = np.random.normal(1600,10,npts)\n",
    "distances = 500*np.random.random(npts)\n",
    "\n",
    "vals = []\n",
    "\n",
    "for idx in range(npts):\n",
    "    \n",
    "    #E_muon = E_muons[idx]\n",
    "    #distance = distances[idx]\n",
    "    \n",
    "    #e_initials_unique = df_eloss['e_initial'].unique()\n",
    "    \n",
    "    #de1, de2, kde1, kde2, xpts, elo, ehi = get_data_and_kde_for_interpolation(E_muon=E_muon, distance=distance, df_eloss=df_eloss, e_initials_unique=e_initials_unique, dwidth_pct=0.05)\n",
    "    \n",
    "    #kde1_norm_vals, kde2_norm_vals, kde3_norm_vals = morph_distributions(E_muon, kde1, kde2, xpts, elo, ehi)\n",
    "    \n",
    "    #cdf1, spl1 = generate_cdf_and_spline(xpts, kde1_norm_vals)\n",
    "    #cdf2, spl2 = generate_cdf_and_spline(xpts, kde2_norm_vals)\n",
    "    cdf3, spl3 = generate_cdf_and_spline(xpts, kde3_norm_vals)\n",
    "\n",
    "    val = generate_data_from_spline(spl3, 1)\n",
    "    if len(val)>0:\n",
    "        vals.append(val[0])\n",
    "\n",
    "print(f\"It took {time.time()-start} seconds to generate {npts} events\")\n",
    "\n",
    "plt.hist(vals,bins=50)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505207bc-fe72-45a5-a8c1-671ca4a62d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it\n",
    "eloss_dict = {}\n",
    "\n",
    "eloss_dict = {}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "nentries = 0\n",
    "for E_muon in np.arange(1000,2000,1000):\n",
    "    \n",
    "    #E_muon = 1600\n",
    "    \n",
    "    eloss_dict[E_muon] = {}\n",
    "    \n",
    "    for distance in np.arange(100,1000,500):\n",
    "    \n",
    "        print(distance)\n",
    "    \n",
    "        #distance = 500\n",
    "        e_initials_unique = df_eloss['e_initial'].unique()\n",
    "        \n",
    "        de1, de2, kde1, kde2, xpts, elo, ehi = get_data_and_kde_for_interpolation(E_muon=E_muon, distance=distance, df_eloss=df_eloss, e_initials_unique=e_initials_unique, dwidth_pct=0.05)\n",
    "        \n",
    "        kde1_norm_vals, kde2_norm_vals, kde3_norm_vals = morph_distributions(E_muon, kde1, kde2, xpts, elo, ehi)\n",
    "        \n",
    "        #cdf1, spl1 = generate_cdf_and_spline(xpts, kde1_norm_vals)\n",
    "        #cdf2, spl2 = generate_cdf_and_spline(xpts, kde2_norm_vals)\n",
    "        cdf3, spl3 = generate_cdf_and_spline(xpts, kde3_norm_vals)\n",
    "        \n",
    "        eloss_dict[E_muon][distance] = spl3\n",
    "\n",
    "        nentries += 1\n",
    "\n",
    "print(f'Time to write {nentries} entries is {time.time() - start} seconds')\n",
    "start = time.time()\n",
    "\n",
    "# Save the spline object to a file using pickle\n",
    "with open('spline_object.pkl', 'wb') as file_handle:\n",
    "    pickle.dump(eloss_dict, file_handle)\n",
    "\n",
    "print(f'Time to write file is {time.time() - start} seconds')\n",
    "start = time.time()\n",
    "\n",
    "# Load the spline object from the file\n",
    "with open('spline_object.pkl', 'rb') as file_handle:\n",
    "    loaded_eloss_dict = pickle.load(file_handle)\n",
    "\n",
    "print(f'Time to read file is {time.time() - start} seconds')\n",
    "start = time.time()\n",
    "\n",
    "\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929ace0-82ab-4276-8e37-57d346fff863",
   "metadata": {},
   "outputs": [],
   "source": [
    "eloss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2241e-274e-4a4e-951a-abc9fb421cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eloss_dict[1600][500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e3efa-12aa-430b-acec-fb8c7cfa3cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b7dc2cc-bf94-442b-82c6-7163009eeace",
   "metadata": {},
   "source": [
    "# Testing the lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00a6eb-768b-45f3-8850-6b6607394631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "class PiecewiseGridSplineLookup:\n",
    "    \"\"\"\n",
    "    Fast O(1) lookup for a dict-of-dicts spline table where\n",
    "    both energy and distance are *piecewise* regular.\n",
    "\n",
    "    Expected table shape:\n",
    "        data = {\n",
    "            100.0: {1.0: spline, 11.0: spline, ...},\n",
    "            110.0: {...},\n",
    "            ...\n",
    "            1000.0: {...},\n",
    "            1100.0: {...},\n",
    "            ...\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: Dict[float, Dict[float, Any]],\n",
    "                 high_dist_step: float = 100.0):\n",
    "        \"\"\"\n",
    "        data: {energy: {distance: spline}}\n",
    "        high_dist_step: distance step to use for E >= 10_000\n",
    "                        (you said 100 for now, might change to 10)\n",
    "        \"\"\"\n",
    "        self._data = data\n",
    "        self._high_dist_step = float(high_dist_step)\n",
    "\n",
    "    # --------------------\n",
    "    # ENERGY SNAPPING\n",
    "    # --------------------\n",
    "    @staticmethod\n",
    "    def _snap_energy(E: float) -> float:\n",
    "        \"\"\"\n",
    "        Snap E to nearest energy according to piecewise rules:\n",
    "\n",
    "        [100, 1000): step 10\n",
    "        [1000, 10_000): step 100\n",
    "        [10_000, 100_000]: step 1000\n",
    "\n",
    "        Clamp below 100 and above 100_000.\n",
    "        \"\"\"\n",
    "        if E <= 100:\n",
    "            return 100.0\n",
    "\n",
    "        # region 1\n",
    "        if E < 1000:\n",
    "            base = 100.0\n",
    "            step = 10.0\n",
    "            idx = int(round((E - base) / step))\n",
    "            val = base + idx * step\n",
    "            # clamp upper edge to 1000\n",
    "            if val >= 1000.0:\n",
    "                val = 1000.0\n",
    "            return val\n",
    "\n",
    "        # region 2\n",
    "        if E < 10_000:\n",
    "            base = 1000.0\n",
    "            step = 100.0\n",
    "            idx = int(round((E - base) / step))\n",
    "            val = base + idx * step\n",
    "            if val >= 10_000.0:\n",
    "                val = 10_000.0\n",
    "            return val\n",
    "\n",
    "        # region 3\n",
    "        if E < 100_000:\n",
    "            base = 10_000.0\n",
    "            step = 1000.0\n",
    "            idx = int(round((E - base) / step))\n",
    "            val = base + idx * step\n",
    "            if val > 100_000.0:\n",
    "                val = 100_000.0\n",
    "            return val\n",
    "\n",
    "        # above max\n",
    "        return 100_000.0\n",
    "\n",
    "    # --------------------\n",
    "    # DISTANCE SNAPPING\n",
    "    # --------------------\n",
    "    def _snap_distance(self, E_key: float, d: float) -> float:\n",
    "        \"\"\"\n",
    "        Snap d to the appropriate distance grid for the energy region.\n",
    "        Rules (from your description):\n",
    "\n",
    "        - for E in [100, 1000):   d = 1..1000   step 10\n",
    "        - for E in [1000, 10_000): d = 1..5000   step 10\n",
    "        - for E in [10_000, 100_000]: d = 1..10_000 step = self._high_dist_step\n",
    "        \"\"\"\n",
    "        if E_key < 1000.0:\n",
    "            d_min = 1.0\n",
    "            d_max = 1000.0\n",
    "            d_step = 10.0\n",
    "        elif E_key < 10_000.0:\n",
    "            d_min = 1.0\n",
    "            d_max = 5000.0\n",
    "            d_step = 10.0\n",
    "        else:\n",
    "            d_min = 1.0\n",
    "            d_max = 10_000.0\n",
    "            d_step = self._high_dist_step\n",
    "\n",
    "        # snap\n",
    "        rel = (d - d_min) / d_step\n",
    "        idx = int(round(rel))\n",
    "        d_val = d_min + idx * d_step\n",
    "\n",
    "        # clamp\n",
    "        if d_val < d_min:\n",
    "            d_val = d_min\n",
    "        if d_val > d_max:\n",
    "            d_val = d_max\n",
    "\n",
    "        return d_val\n",
    "\n",
    "    # --------------------\n",
    "    # PUBLIC LOOKUP\n",
    "    # --------------------\n",
    "    def get(self, E: float, d: float):\n",
    "        \"\"\"\n",
    "        Return the spline for the closest (E, d) on the piecewise grid.\n",
    "        \"\"\"\n",
    "        E_key = self._snap_energy(E)\n",
    "        inner = self._data.get(E_key)\n",
    "        if inner is None:\n",
    "            raise KeyError(f\"No splines stored for energy {E_key}\")\n",
    "\n",
    "        d_key = self._snap_distance(E_key, d)\n",
    "        try:\n",
    "            return inner[d_key]\n",
    "        except KeyError:\n",
    "            # in case your stored dict uses ints instead of floats\n",
    "            # we can try a fallback\n",
    "            alt_key = int(d_key) if d_key.is_integer() else d_key\n",
    "            return inner[alt_key]\n",
    "\n",
    "\n",
    "\n",
    "# fake spline class\n",
    "class FakeSpline:\n",
    "    def __init__(self, name): self.name = name\n",
    "    def __repr__(self): return f\"Spline({self.name})\"\n",
    "\n",
    "\n",
    "def build_fake_data(high_dist_step=100.0):\n",
    "    data = {}\n",
    "\n",
    "    # region 1: 100..1000 step 10, d 1..1000 step 10\n",
    "    E = 100\n",
    "    while E <= 1000:\n",
    "        d_dict = {}\n",
    "        d = 1\n",
    "        while d <= 1000:\n",
    "            d_dict[float(d)] = FakeSpline(f\"E{E}_d{d}\")\n",
    "            d += 10\n",
    "        data[float(E)] = d_dict\n",
    "        E += 10\n",
    "\n",
    "    # region 2: 1000..10_000 step 100, d 1..5000 step 10\n",
    "    E = 1000\n",
    "    while E <= 10_000:\n",
    "        d_dict = {}\n",
    "        d = 1\n",
    "        while d <= 5000:\n",
    "            d_dict[float(d)] = FakeSpline(f\"E{E}_d{d}\")\n",
    "            d += 10\n",
    "        data[float(E)] = d_dict\n",
    "        E += 100\n",
    "\n",
    "    # region 3: 10_000..100_000 step 1000, d 1..10_000 step high_dist_step\n",
    "    E = 10_000\n",
    "    while E <= 100_000:\n",
    "        d_dict = {}\n",
    "        d = 1\n",
    "        while d <= 10_000:\n",
    "            d_dict[float(d)] = FakeSpline(f\"E{E}_d{d}\")\n",
    "            d += high_dist_step\n",
    "        data[float(E)] = d_dict\n",
    "        E += 1000\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73f113-7a20-4d9d-b5e7-dfe09b8ae519",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = build_fake_data(high_dist_step=100.0)\n",
    "lookup = PiecewiseGridSplineLookup(data, high_dist_step=100.0)\n",
    "\n",
    "s = lookup.get(190, 14)      # E=190 → 190 (region1), d=14 → 11\n",
    "print(s)\n",
    "s2 = lookup.get(9800, 432)   # E=9800 → 9800, d=432 → 431 (actually 431 → snaps to 431? no, 1+43*10=431, 1+44*10=441, so 432→431 or 441 depending on rounding)\n",
    "print(s2)\n",
    "s3 = lookup.get(25_000, 1234)  # high region\n",
    "print(s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a34fe0-006c-4fff-9b5f-0a3a1b6c765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_region1():\n",
    "    data = {\n",
    "        100.0: {1.0: \"E100_d1\", 11.0: \"E100_d11\", 21.0: \"E100_d21\"},\n",
    "        110.0: {1.0: \"E110_d1\"},\n",
    "    }\n",
    "    lookup = PiecewiseGridSplineLookup(data)\n",
    "\n",
    "    # 105 → snaps to 100 or 110? 105 is halfway. round() will send (105-100)/10=0.5 → round(0.5)=0 → 100\n",
    "    assert lookup.get(105, 12) == \"E100_d11\"\n",
    "\n",
    "def test_region2():\n",
    "    data = {\n",
    "        1000.0: {1.0: \"E1000_d1\", 11.0: \"E1000_d11\"},\n",
    "        1100.0: {1.0: \"E1100_d1\"},\n",
    "    }\n",
    "    lookup = PiecewiseGridSplineLookup(data)\n",
    "\n",
    "    assert lookup.get(1030, 14) == \"E1000_d11\"\n",
    "    assert lookup.get(1080, 2) == \"E1100_d1\"  # 1080 closer to 1100 than 1000\n",
    "\n",
    "def test_region3():\n",
    "    data = {\n",
    "        10_000.0: {1.0: \"E10000_d1\", 101.0: \"E10000_d101\"},\n",
    "        11_000.0: {1.0: \"E11000_d1\"},\n",
    "    }\n",
    "    lookup = PiecewiseGridSplineLookup(data, high_dist_step=100.0)\n",
    "\n",
    "    assert lookup.get(10_200, 120) == \"E10000_d101\"\n",
    "    assert lookup.get(10_700, 3) == \"E11000_d1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a341005-1166-46b3-a09f-904d26c03c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = PiecewiseGridSplineLookup(data, high_dist_step=10.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508f0c4-bb5f-4d2b-b233-0be793447bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_region1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0114b8-820a-4adf-9472-149c70fc24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Fake spline (stand-in for real interpolation object)\n",
    "# ---------------------------------------------------\n",
    "class FakeSpline:\n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Spline({self.name})\"\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Your piecewise O(1) lookup\n",
    "# ---------------------------------------------------\n",
    "from typing import Any, Dict\n",
    "from bisect import bisect_right\n",
    "\n",
    "\n",
    "class PiecewiseGridSplineLookup:\n",
    "    def __init__(self, data: Dict[float, Dict[float, Any]],\n",
    "                 high_dist_step: float = 100.0):\n",
    "        # normalize all outer/inner keys to float so we don't fight ints vs floats\n",
    "        self._data: Dict[float, Dict[float, Any]] = {}\n",
    "        for E, inner in data.items():\n",
    "            E_key = float(E)\n",
    "            self._data[E_key] = {float(d): v for d, v in inner.items()}\n",
    "        self._high_dist_step = float(high_dist_step)\n",
    "\n",
    "    # -------------------- ENERGY --------------------\n",
    "    @staticmethod\n",
    "    def _snap_energy(E: float) -> float:\n",
    "        if E <= 100:\n",
    "            return 100.0\n",
    "\n",
    "        # region 1: 100..1000 step 10\n",
    "        if E < 1000:\n",
    "            base = 100.0\n",
    "            step = 10.0\n",
    "            idx = int(round((E - base) / step))\n",
    "            val = base + idx * step\n",
    "            if val >= 1000.0:\n",
    "                val = 1000.0\n",
    "            return val\n",
    "\n",
    "        # region 2: 1000..10_000 step 100\n",
    "        if E < 10_000:\n",
    "            base = 1000.0\n",
    "            step = 100.0\n",
    "            idx = int(round((E - base) / step))\n",
    "            val = base + idx * step\n",
    "            if val >= 10_000.0:\n",
    "                val = 10_000.0\n",
    "            return val\n",
    "\n",
    "        # region 3: 10_000..100_000 step 1000\n",
    "        if E < 100_000:\n",
    "            base = 10_000.0\n",
    "            step = 1000.0\n",
    "            idx = int(round((E - base) / step))\n",
    "            val = base + idx * step\n",
    "            if val > 100_000.0:\n",
    "                val = 100_000.0\n",
    "            return val\n",
    "\n",
    "        return 100_000.0\n",
    "\n",
    "    # -------------------- DISTANCE (rule-based) --------------------\n",
    "    def _snap_distance_rule_based(self, E_key: float, d: float) -> float:\n",
    "        \"\"\"\n",
    "        What *we think* the distance grid is, based on your rules.\n",
    "        This may produce a value that is slightly above the actual\n",
    "        keys in the dict, so we'll still verify against real keys.\n",
    "        \"\"\"\n",
    "        if E_key < 1000.0:\n",
    "            d_min = 1.0\n",
    "            d_max = 1000.0\n",
    "            d_step = 10.0\n",
    "        elif E_key < 10_000.0:\n",
    "            d_min = 1.0\n",
    "            d_max = 5000.0\n",
    "            d_step = 10.0\n",
    "        else:\n",
    "            d_min = 1.0\n",
    "            d_max = 10_000.0\n",
    "            d_step = self._high_dist_step\n",
    "\n",
    "        rel = (d - d_min) / d_step\n",
    "        idx = int(round(rel))\n",
    "        d_val = d_min + idx * d_step\n",
    "\n",
    "        # tentative clamp to \"intended\" max\n",
    "        if d_val < d_min:\n",
    "            d_val = d_min\n",
    "        if d_val > d_max:\n",
    "            d_val = d_max\n",
    "\n",
    "        return d_val\n",
    "\n",
    "    # -------------------- PUBLIC LOOKUP --------------------\n",
    "    def get(self, E: float, d: float):\n",
    "        # 1. snap energy\n",
    "        E_key = self._snap_energy(E)\n",
    "\n",
    "        inner = self._data.get(E_key)\n",
    "        if inner is None:\n",
    "            raise KeyError(f\"No splines stored for energy {E_key}\")\n",
    "\n",
    "        # 2. snap distance using rule\n",
    "        d_guess = self._snap_distance_rule_based(E_key, d)\n",
    "        d_guess = float(d_guess)\n",
    "\n",
    "        # 2a. fast path: exact match\n",
    "        if d_guess in inner:\n",
    "            return inner[d_guess]\n",
    "\n",
    "        # 3. robust fallback: pick the closest *lower* (or last) real key\n",
    "        #    this makes us immune to 9901 vs 10000 mismatches\n",
    "        real_ds = sorted(inner.keys())  # size is small (<=100), OK\n",
    "        # find insertion point to the right of d_guess\n",
    "        pos = bisect_right(real_ds, d_guess)\n",
    "        if pos == 0:\n",
    "            # everything is larger → take the smallest\n",
    "            d_key = real_ds[0]\n",
    "        else:\n",
    "            # take the greatest <= d_guess\n",
    "            d_key = real_ds[pos - 1]\n",
    "\n",
    "        return inner[d_key]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Bisect-based version to compare\n",
    "# ---------------------------------------------------\n",
    "from bisect import bisect_left\n",
    "\n",
    "\n",
    "class BisectSplineLookup:\n",
    "    def __init__(self, data: Dict[float, Dict[float, Any]]):\n",
    "        self._data = data\n",
    "        self._energies = sorted(data.keys())\n",
    "        self._dists_for_E = {\n",
    "            E: sorted(inner.keys()) for E, inner in data.items()\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _closest(sorted_list, x):\n",
    "        i = bisect_left(sorted_list, x)\n",
    "        if i == 0:\n",
    "            return sorted_list[0]\n",
    "        if i == len(sorted_list):\n",
    "            return sorted_list[-1]\n",
    "        before = sorted_list[i - 1]\n",
    "        after = sorted_list[i]\n",
    "        return before if abs(before - x) <= abs(after - x) else after\n",
    "\n",
    "    def get(self, E: float, d: float):\n",
    "        E_key = self._closest(self._energies, E)\n",
    "        d_list = self._dists_for_E[E_key]\n",
    "        d_key = self._closest(d_list, d)\n",
    "        return self._data[E_key][d_key]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Build fake data (your piecewise grid)\n",
    "# ---------------------------------------------------\n",
    "def build_fake_data(high_dist_step=100.0):\n",
    "    data = {}\n",
    "\n",
    "    # region 1: 100..1000 step 10, d 1..1000 step 10\n",
    "    E = 100\n",
    "    while E <= 1000:\n",
    "        d_dict = {}\n",
    "        d = 1\n",
    "        while d <= 1000:\n",
    "            d_dict[float(d)] = FakeSpline(f\"E{E}_d{d}\")\n",
    "            d += 10\n",
    "        data[float(E)] = d_dict\n",
    "        E += 10\n",
    "\n",
    "    # region 2: 1000..10_000 step 100, d 1..5000 step 10\n",
    "    E = 1000\n",
    "    while E <= 10_000:\n",
    "        d_dict = {}\n",
    "        d = 1\n",
    "        while d <= 5000:\n",
    "            d_dict[float(d)] = FakeSpline(f\"E{E}_d{d}\")\n",
    "            d += 10\n",
    "        data[float(E)] = d_dict\n",
    "        E += 100\n",
    "\n",
    "    # region 3: 10_000..100_000 step 1000, d 1..10_000 step high_dist_step\n",
    "    E = 10_000\n",
    "    while E <= 100_000:\n",
    "        d_dict = {}\n",
    "        d = 1\n",
    "        while d <= 10_000:\n",
    "            d_dict[float(d)] = FakeSpline(f\"E{E}_d{d}\")\n",
    "            d += high_dist_step\n",
    "        data[float(E)] = d_dict\n",
    "        E += 1000\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Timing helper\n",
    "# ---------------------------------------------------\n",
    "def time_lookup(obj, n=100_000):\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(n):\n",
    "        # random energy between 80 and 120_000 to test clamping\n",
    "        E = random.uniform(80, 120_000)\n",
    "        # random distance between 0 and 12_000\n",
    "        d = random.uniform(0, 12_000)\n",
    "        _ = obj.get(E, d)\n",
    "    t1 = time.perf_counter()\n",
    "    dt = t1 - t0\n",
    "    per = dt / n\n",
    "    print(f\"{obj.__class__.__name__}: {n} lookups in {dt:.4f}s -> {per*1e6:.2f} µs/lookup\")\n",
    "\n",
    "def normalize_table(raw_data, *, to_float=True):\n",
    "    norm = {}\n",
    "    for E, inner in raw_data.items():\n",
    "        E_key = float(E) if to_float else E\n",
    "        new_inner = {}\n",
    "        for d, spline in inner.items():\n",
    "            d_key = float(d) if to_float else d\n",
    "            new_inner[d_key] = spline\n",
    "        norm[E_key] = new_inner\n",
    "    return norm\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# main\n",
    "# ---------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(42)\n",
    "\n",
    "    print(\"Building fake data...\")\n",
    "    data = normalize_table(build_fake_data(high_dist_step=100.0))\n",
    "\n",
    "    print(\"Constructing lookups...\")\n",
    "    piecewise_lookup = PiecewiseGridSplineLookup(data, high_dist_step=100.0)\n",
    "    bisect_lookup = BisectSplineLookup(data)\n",
    "\n",
    "    print(\"\\nTiming...\")\n",
    "    time_lookup(piecewise_lookup, n=200_000)\n",
    "    time_lookup(bisect_lookup, n=200_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b7f64-d8b7-4b97-bd25-1de0961ae68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized\n",
    "import numpy as np\n",
    "\n",
    "class PiecewiseGridSplineLookupVec:\n",
    "    def __init__(self, base_lookup):\n",
    "        \"\"\"\n",
    "        base_lookup: an instance of your working PiecewiseGridSplineLookup\n",
    "                     (the robust one we just fixed)\n",
    "        \"\"\"\n",
    "        self.base = base_lookup\n",
    "\n",
    "    def snap_energies(self, E: np.ndarray) -> np.ndarray:\n",
    "        E = np.asarray(E, dtype=float)\n",
    "        out = np.empty_like(E)\n",
    "\n",
    "        # regions\n",
    "        m1 = E < 100\n",
    "        m2 = (E >= 100) & (E < 1000)\n",
    "        m3 = (E >= 1000) & (E < 10_000)\n",
    "        m4 = (E >= 10_000) & (E < 100_000)\n",
    "        m5 = E >= 100_000\n",
    "\n",
    "        # below 100 → 100\n",
    "        out[m1] = 100.0\n",
    "\n",
    "        # 100..1000 step 10\n",
    "        tmp = E[m2]\n",
    "        base = 100.0\n",
    "        step = 10.0\n",
    "        idx = np.rint((tmp - base) / step).astype(int)\n",
    "        val = base + idx * step\n",
    "        val = np.minimum(val, 1000.0)\n",
    "        out[m2] = val\n",
    "\n",
    "        # 1000..10_000 step 100\n",
    "        tmp = E[m3]\n",
    "        base = 1000.0\n",
    "        step = 100.0\n",
    "        idx = np.rint((tmp - base) / step).astype(int)\n",
    "        val = base + idx * step\n",
    "        val = np.minimum(val, 10_000.0)\n",
    "        out[m3] = val\n",
    "\n",
    "        # 10_000..100_000 step 1000\n",
    "        tmp = E[m4]\n",
    "        base = 10_000.0\n",
    "        step = 1000.0\n",
    "        idx = np.rint((tmp - base) / step).astype(int)\n",
    "        val = base + idx * step\n",
    "        val = np.minimum(val, 100_000.0)\n",
    "        out[m4] = val\n",
    "\n",
    "        # above max\n",
    "        out[m5] = 100_000.0\n",
    "\n",
    "        return out\n",
    "\n",
    "    def snap_distances(self, E_snap: np.ndarray, d: np.ndarray) -> np.ndarray:\n",
    "        d = np.asarray(d, dtype=float)\n",
    "        E_snap = np.asarray(E_snap, dtype=float)\n",
    "        out = np.empty_like(d)\n",
    "\n",
    "        # region 1: E < 1000 → d 1..1000 step 10\n",
    "        r1 = E_snap < 1000.0\n",
    "        if np.any(r1):\n",
    "            d1 = d[r1]\n",
    "            d_min, d_max, step = 1.0, 1000.0, 10.0\n",
    "            rel = (d1 - d_min) / step\n",
    "            idx = np.rint(rel).astype(int)\n",
    "            d_val = d_min + idx * step\n",
    "            d_val = np.clip(d_val, d_min, d_max)\n",
    "            out[r1] = d_val\n",
    "\n",
    "        # region 2: 1000 ≤ E < 10_000 → d 1..5000 step 10\n",
    "        r2 = (E_snap >= 1000.0) & (E_snap < 10_000.0)\n",
    "        if np.any(r2):\n",
    "            d2 = d[r2]\n",
    "            d_min, d_max, step = 1.0, 5000.0, 10.0\n",
    "            rel = (d2 - d_min) / step\n",
    "            idx = np.rint(rel).astype(int)\n",
    "            d_val = d_min + idx * step\n",
    "            d_val = np.clip(d_val, d_min, d_max)\n",
    "            out[r2] = d_val\n",
    "\n",
    "        # region 3: E ≥ 10_000 → d 1..10_000 step = lookup.high_dist_step,\n",
    "        # BUT we must align to actual max present in the dict.\n",
    "        r3 = E_snap >= 10_000.0\n",
    "        if np.any(r3):\n",
    "            d3 = d[r3]\n",
    "            step = self.base._high_dist_step\n",
    "            d_min, d_max = 1.0, 10_000.0\n",
    "            # compute actual max like we did in the robust version\n",
    "            kmax = int((d_max - d_min) // step)\n",
    "            actual_max = d_min + kmax * step\n",
    "\n",
    "            rel = (d3 - d_min) / step\n",
    "            idx = np.rint(rel).astype(int)\n",
    "            d_val = d_min + idx * step\n",
    "            d_val = np.clip(d_val, d_min, actual_max)\n",
    "            out[r3] = d_val\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_many(self, E_arr, d_arr):\n",
    "        \"\"\"\n",
    "        Vectorized front-end: returns a Python list of splines.\n",
    "        (Returning ndarray of objects also possible.)\n",
    "        \"\"\"\n",
    "        E_arr = np.asarray(E_arr, dtype=float)\n",
    "        d_arr = np.asarray(d_arr, dtype=float)\n",
    "        E_snap = self.snap_energies(E_arr)\n",
    "        d_snap = self.snap_distances(E_snap, d_arr)\n",
    "\n",
    "        result = []\n",
    "        data = self.base._data  # already normalized\n",
    "\n",
    "        for E_key, d_key in zip(E_snap, d_snap):\n",
    "            inner = data[E_key]\n",
    "            # fast path\n",
    "            if d_key in inner:\n",
    "                result.append(inner[d_key])\n",
    "            else:\n",
    "                # robust fallback: choose closest lower real key\n",
    "                real_ds = sorted(inner.keys())\n",
    "                # since small, just scan backward\n",
    "                chosen = real_ds[0]\n",
    "                for x in real_ds:\n",
    "                    if x <= d_key:\n",
    "                        chosen = x\n",
    "                    else:\n",
    "                        break\n",
    "                result.append(inner[chosen])\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026f16e-8e05-427a-a6b0-c450c19978bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume you already built `data` and `lookup = PiecewiseGridSplineLookup(data, ...)`\n",
    "vec = PiecewiseGridSplineLookupVec(lookup)\n",
    "\n",
    "#E_batch = np.array([190, 2500, 64000, 120000])\n",
    "#d_batch = np.array([14, 1234, 9999, 50])\n",
    "\n",
    "npts = 100000\n",
    "E_batch = 1000*np.random.random(npts)\n",
    "d_batch = 1000*np.random.random(npts)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "splines = vec.get_many(E_batch, d_batch)\n",
    "print(f'Time to run: {time.time() - start} seconds')\n",
    "\n",
    "#time_lookup(vec.get_many(E_batch, d_batch), n=2)\n",
    "\n",
    "for s in splines[0:10]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dc9be-1b67-4a0e-9a54-aa50790cc71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff4348-b415-4fab-833b-c6bc040ba7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f025d44-f1fb-47e4-8de4-c0b565caca86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636a0a6-ac64-456f-8a45-b5d6d8e433fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster\n",
    "\n",
    "distance = 75\n",
    "# This needs to be greater than 100, since that is the lowest value we have\n",
    "E_muon = 115\n",
    "\n",
    "#e_initials = [110, 120]\n",
    "e_initials_unique = df_eloss['e_initial'].unique()\n",
    "\n",
    "#############################################\n",
    "\n",
    "# Find window of E\n",
    "\n",
    "# My own \n",
    "d = distance\n",
    "dwidth = 0.05 * d\n",
    "print(d,dwidth)\n",
    "\n",
    "# Find the range in which we will look\n",
    "\n",
    "#print(e_initials)\n",
    "elo,ehi = find_neighbors(e_initials_unique, E_muon)\n",
    "delta_e = ehi - elo\n",
    "\n",
    "print(E_muon, delta_e, elo, ehi)\n",
    "\n",
    "#############################################\n",
    "\n",
    "filter_e1 = (e_initials==elo)\n",
    "filter_e2 = (e_initials==ehi)\n",
    "filter_d1 = (z_vals>=d-dwidth) & (z_vals<=d+dwidth)\n",
    "\n",
    "\n",
    "de1 = df_eloss[filter_e1 & filter_d1]['e']\n",
    "de2 = df_eloss[filter_e2 & filter_d1]['e']\n",
    "\n",
    "\n",
    "#####################################\n",
    "\n",
    "bandwidth = 0.1\n",
    "kde1 = gaussian_kde(de1, bw_method=bandwidth)\n",
    "kde2 = gaussian_kde(de2, bw_method=bandwidth)\n",
    "\n",
    "#####################################\n",
    "print(\"ranges\")\n",
    "#eranges = ehi_vals - elo_vals\n",
    "#print(elo_vals,'\\n', ehi_vals, '\\n', eranges)\n",
    "\n",
    "\n",
    "elo_vals, ehi_vals, elo_min,ehi_max = find_de_ranges(de1, de2)\n",
    "\n",
    "#xpts = np.linspace(elo_min,E_muon,100)\n",
    "xpts = np.linspace(elo_min,ehi_max,500)\n",
    "\n",
    "\n",
    "kde1_vals = kde1.pdf(xpts)\n",
    "kde2_vals = kde2.pdf(xpts)\n",
    "\n",
    "fig,axes = plt.subplots(1,3,figsize=(12,4))\n",
    "axes[0].hist(de1, range=(elo_min,ehi_max), bins=200, density=True)\n",
    "axes[0].plot(xpts, kde1_vals, lw=2)\n",
    "axes[0].set_xlabel(r'$\\Delta$ E (GeV)')\n",
    "axes[0].set_ylabel('Final energy (GeV)')\n",
    "axes[0].set_title(f'Initial energy: {elo} GeV')\n",
    "\n",
    "axes[1].hist(de2, range=(elo_min,ehi_max), bins=200, density=True)\n",
    "axes[1].plot(xpts, kde2_vals, lw=2)\n",
    "axes[1].set_xlabel(r'$\\Delta$ E (GeV)')\n",
    "axes[1].set_ylabel('Final energy (GeV)')\n",
    "axes[1].set_title(f'Initial energy: {ehi} GeV')\n",
    "\n",
    "axes[2].hist(de1, range=(elo_min,ehi_max), bins=200, density=True, label=f'E$_i$={elo} GeV')\n",
    "axes[2].plot(xpts, kde1_vals, lw=2)\n",
    "axes[2].hist(de2, range=(elo_min,ehi_max), bins=200, density=True, label=f'E$_i$={ehi} GeV')\n",
    "axes[2].plot(xpts, kde2_vals, lw=2)\n",
    "axes[2].set_xlabel(r'$\\Delta$ E (GeV)')\n",
    "axes[2].set_ylabel('Final energy (GeV)')\n",
    "axes[2].legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f261aa4-fe74-4d6b-b258-361bb99d57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kde2_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f240f4-2ae8-42a2-b4c8-3d3e3796d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Normaize the x-scale\n",
    "e_ranges = ehi_vals - elo_vals\n",
    "# de1\n",
    "npts = 500\n",
    "xpts1 = np.linspace(elo_vals[0], ehi_vals[0], npts)\n",
    "xpts2 = np.linspace(elo_vals[1], ehi_vals[1], npts)\n",
    "\n",
    "#kde1_norm_vals = kde1.pdf(xpts1)\n",
    "#kde2_norm_vals = kde2.pdf(xpts2)\n",
    "\n",
    "kde1_norm_vals = kde1.pdf(xpts)\n",
    "kde2_norm_vals = kde2.pdf(xpts)\n",
    "\n",
    "\n",
    "#kde1_integral = integrate.trapezoid(kde1_norm_vals, xpts1)\n",
    "#kde2_integral = integrate.trapezoid(kde2_norm_vals, xpts2)\n",
    "\n",
    "kde1_integral = integrate.trapezoid(kde1_norm_vals, xpts)\n",
    "kde2_integral = integrate.trapezoid(kde2_norm_vals, xpts)\n",
    "\n",
    "\n",
    "print(kde1_integral, kde2_integral)\n",
    "\n",
    "# Normalize the y-values so we can interpret it as probability density\n",
    "# Need to consider the distances between points\n",
    "#binwidth1 = xpts1[1] - xpts1[0]\n",
    "#binwidth2 = xpts2[1] - xpts2[0]\n",
    "\n",
    "kde1_norm_vals /= kde1_integral\n",
    "kde2_norm_vals /= kde2_integral\n",
    "\n",
    "scale_factor = (ehi - E_muon)/(ehi-elo)\n",
    "print(f'{E_muon=}   {elo=}  {ehi=}  {scale_factor=}')\n",
    "kde_between_norm_vals =  (scale_factor*kde1_norm_vals) + ((1-scale_factor)*kde2_norm_vals)\n",
    "\n",
    "\n",
    "# Normalize but also take into account the bin spacing\n",
    "#binwidth = xpts_new[1] - xpts_new[0]\n",
    "#kde_between_norm_vals /= sum(kde_between_norm_vals)\n",
    "#kde_between_norm_vals /= binwidth\n",
    "\n",
    "\n",
    "#elo_new = (scale_factor*elo_vals[0]) + ((1-scale_factor)*elo_vals[1])\n",
    "#ehi_new = (scale_factor*ehi_vals[0]) + ((1-scale_factor)*ehi_vals[1])\n",
    "\n",
    "#print(f\"elo_new: {elo_new}     ehi_new: {ehi_new}\")\n",
    "#xpts_new = np.linspace(elo_new, ehi_new, npts)\n",
    "\n",
    "#kde_between_integral = integrate.trapezoid(kde_between_norm_vals, xpts_new)\n",
    "kde_between_integral = integrate.trapezoid(kde_between_norm_vals, xpts)\n",
    "kde_between_norm_vals /= kde_between_integral\n",
    "\n",
    "\n",
    "\n",
    "xpts_norm = np.linspace(0,1, npts)\n",
    "\n",
    "fig,axes = plt.subplots(3,1,figsize=(12,12))\n",
    "axes[0].plot(xpts, kde1_norm_vals, lw=2, label=f'{elo}')\n",
    "axes[0].plot(xpts, kde2_norm_vals, lw=2,label=f'{ehi}')\n",
    "axes[0].legend()\n",
    "\n",
    "#axes[1].plot(xpts_norm, kde1_norm_vals, lw=2, label=f'{elo}')\n",
    "#axes[1].plot(xpts_norm, kde2_norm_vals, lw=2, label=f'{ehi}')\n",
    "#axes[1].plot(xpts_norm, kde_between_norm_vals, lw=2, label=f'{E_muon}')\n",
    "#axes[1].legend()\n",
    "\n",
    "axes[1].plot(xpts, kde1_norm_vals, lw=2, label=f'{elo}')\n",
    "axes[1].plot(xpts, kde2_norm_vals, lw=2,label=f'{ehi}')\n",
    "axes[1].plot(xpts, kde_between_norm_vals, lw=2, label=f'{E_muon}')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "print(sum(kde1_norm_vals))\n",
    "print(sum(kde2_norm_vals))\n",
    "print(sum(kde_between_norm_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d8f98-733f-4670-8b8b-dd5ac8811601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cdf(xpts, ypts):\n",
    "\n",
    "    # Sample points\n",
    "    dx = xpts[1] - xpts[0]\n",
    "    #print(dx)\n",
    "    #print(ypts)\n",
    "    \n",
    "    cdf = np.cumsum(ypts)*dx\n",
    "    #print(cdf)\n",
    "    \n",
    "    cdf /= cdf[-1]\n",
    "\n",
    "    return cdf\n",
    "\n",
    "cdf1 = generate_cdf(xpts, kde1_norm_vals)\n",
    "cdf2 = generate_cdf(xpts, kde2_norm_vals)\n",
    "cdf3 = generate_cdf(xpts, kde_between_norm_vals)\n",
    "\n",
    "\n",
    "print(\"Making the spline........\")\n",
    "\n",
    "spl = CubicSpline(xpts, cdf3)\n",
    "\n",
    "\n",
    "####\n",
    "#spl = CubicSpline(xpts_new, cdf_between)\n",
    "\n",
    "#new_vals = spl.solve(new_vals_rand)\n",
    "\n",
    "#print(new_vals_rand)\n",
    "#print()\n",
    "#enew_min = min(xpts_new)\n",
    "#enew_max = max(xpts_new)\n",
    "\n",
    "print(\"Generating random points..........\")\n",
    "\n",
    "start = time.time()\n",
    "new_npts = 5000\n",
    "ynew_pts = []\n",
    "new_vals_rand = np.random.random(new_npts)\n",
    "\n",
    "for i in range(new_npts):\n",
    "    \n",
    "    ynew = spl.solve(new_vals_rand[i])\n",
    "    filter = (ynew>enew_min) & (ynew<enew_max)\n",
    "    ynew = ynew[filter]\n",
    "    if len(ynew)==1:\n",
    "        ynew=ynew[0]\n",
    "        #print(ynew)\n",
    "        ynew_pts.append(ynew)\n",
    "\n",
    "print(f'Generated {new_npts} points in {time.time() - start} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c528e7-7c80-4fda-bf96-3bac8610359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_intermediate = gaussian_kde(kde_between_norm_vals)\n",
    "\n",
    "ynew_pts2 = kde_intermediate.resample(10000)\n",
    "#print(ynew_pts2[0])\n",
    "plt.hist(ynew_pts2[0],bins=50)\n",
    "\n",
    "fig,axes = plt.subplots(3,1,figsize=(12,12))\n",
    "axes[0].plot(xpts, cdf1, lw=2, label=f'{elo}')\n",
    "axes[0].plot(xpts, cdf2, lw=2,label=f'{ehi}')\n",
    "axes[0].plot(xpts,  cdf3, lw=2, label=f'{E_muon}')\n",
    "axes[0].legend()\n",
    "\n",
    "#axes[1].hist(de1,     range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{elo}')\n",
    "axes[1].hist(de2,     range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{ehi}')\n",
    "axes[1].hist(ynew_pts,range=(elo_min,ehi_max), bins=200, density=True, alpha=0.75, label=f'{E_muon}')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].hist(de1,     range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{elo}')\n",
    "#axes[1].hist(de2,     range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{ehi}')\n",
    "axes[2].hist(ynew_pts,range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{E_muon}')\n",
    "axes[2].legend()\n",
    "\n",
    "\n",
    "#axes[2].hist(de1, range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{elo}')\n",
    "#aes[2].hist(de1, range=(elo_min,ehi_max), bins=200, density=True, alpha=0.4, label=f'{ehi}')\n",
    "#axes[2].hist(ynew_pts,range=(elo_min,ehi_max), bins=200, density=True, alpha=0.75, label=f'{E_muon}')\n",
    "#axes[2].legend()\n",
    "\n",
    ";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa687b10-a8d7-47ad-99f9-8a7cdc980365",
   "metadata": {},
   "outputs": [],
   "source": [
    "spl.solve(0.5, extrapolate='periodic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9dc83d-c22e-4321-a2ba-ec9e2a184e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "\n",
    "\n",
    "for i in range(0,2):\n",
    "    if i==0:\n",
    "        y = elo\n",
    "        z = kde1_vals\n",
    "    else:\n",
    "        y = ehi\n",
    "        z = kde2_vals\n",
    "    ax.fill_between(xpts, y, z,\n",
    "                    xpts, y, 0,\n",
    "                    facecolors='r', alpha=.7)\n",
    "\n",
    "\n",
    "####################################################\n",
    "\n",
    "# Frequencies\n",
    "\n",
    "\n",
    "#e_range = ehi_max[i] - elo_min[i]\n",
    "#xpts -= elo_min[i]\n",
    "#xpts /= e_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba2792-7b1a-43be-94fa-9f1d3cfb5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define the x-axis for plotting\n",
    "x = np.linspace(-5, 10, 500)\n",
    "\n",
    "# 2. Define the two initial distributions (e.g., two normal distributions)\n",
    "dist1 = norm(loc=0, scale=1)   # Mean=0, StdDev=1\n",
    "dist2 = norm(loc=5, scale=2)   # Mean=5, StdDev=2\n",
    "\n",
    "pdf1 = dist1.pdf(x)\n",
    "pdf2 = dist2.pdf(x)\n",
    "\n",
    "# 3. Create morphed distributions by varying alpha\n",
    "alphas = np.linspace(0, 1, 5)  # Weights for the morphing\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, pdf1, label='Distribution 1 (α=0)', linestyle='--', color='blue')\n",
    "plt.plot(x, pdf2, label='Distribution 2 (α=1)', linestyle='--', color='red')\n",
    "\n",
    "for alpha in alphas:\n",
    "    if alpha == 0 or alpha == 1:\n",
    "        continue\n",
    "    # Linearly interpolate the PDFs\n",
    "    morphed_pdf = (1 - alpha) * pdf1 + alpha * pdf2\n",
    "    plt.plot(x, morphed_pdf, label=f'Morphed (α={alpha:.1f})')\n",
    "\n",
    "plt.title('Morphing Two Distributions with PDF Interpolation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a1cfa-8bb9-40e5-aade-3abbb0f926f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define initial distributions and sample from them\n",
    "np.random.seed(42)\n",
    "samples1 = norm.rvs(loc=0, scale=1, size=1000)\n",
    "samples2 = norm.rvs(loc=5, scale=2, size=1000)\n",
    "\n",
    "# 2. Compute empirical CDFs for each set of samples\n",
    "ecdf1_x = np.sort(samples1)\n",
    "ecdf1_y = np.linspace(0, 1, len(samples1))\n",
    "ecdf2_x = np.sort(samples2)\n",
    "ecdf2_y = np.linspace(0, 1, len(samples2))\n",
    "\n",
    "# 3. Interpolate quantiles (inverse CDF)\n",
    "quantiles_y = np.linspace(0, 1, 500)\n",
    "interp_q1 = interp1d(ecdf1_y, ecdf1_x, bounds_error=False, fill_value=(ecdf1_x[0], ecdf1_x[-1]))\n",
    "interp_q2 = interp1d(ecdf2_y, ecdf2_x, bounds_error=False, fill_value=(ecdf2_x[0], ecdf2_x[-1]))\n",
    "\n",
    "# 4. Morph and visualize\n",
    "alphas = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Linearly interpolate quantiles\n",
    "    morphed_quantiles_x = (1 - alpha) * interp_q1(quantiles_y) + alpha * interp_q2(quantiles_y)\n",
    "    \n",
    "    # Plot the resulting distribution as a histogram\n",
    "    plt.hist(morphed_quantiles_x, bins=50, density=True, histtype='step', \n",
    "             label=f'Morphed (α={alpha:.2f})', alpha=0.8, range=(-5, 10))\n",
    "\n",
    "plt.title('Morphing Two Distributions with Quantile Interpolation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07def6da-b8f0-43ec-a419-1ff488ceb716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf27a16a-682f-447f-a9d5-10da7501fb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee8f6c-8daf-4ee0-88d7-c13836cb49e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad63ea-5ffd-4f89-b76d-ef3f6b1619c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98d08b46-4d61-4a75-a352-2a6435ee056b",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/neighbors/plot_kde_1d.html#sphx-glr-auto-examples-neighbors-plot-kde-1d-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a215565-e966-462e-9a8d-d16dfe970f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Plot the progression of histograms to kernels\n",
    "np.random.seed(1)\n",
    "N = 20\n",
    "X = np.concatenate(\n",
    "    (np.random.normal(0, 1, int(0.3 * N)), np.random.normal(5, 1, int(0.7 * N)))\n",
    ")[:, np.newaxis]\n",
    "X_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n",
    "bins = np.linspace(-5, 10, 10)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "# histogram 1\n",
    "ax[0, 0].hist(X[:, 0], bins=bins, fc=\"#AAAAFF\", density=True)\n",
    "ax[0, 0].text(-3.5, 0.31, \"Histogram\")\n",
    "\n",
    "# histogram 2\n",
    "ax[0, 1].hist(X[:, 0], bins=bins + 0.75, fc=\"#AAAAFF\", density=True)\n",
    "ax[0, 1].text(-3.5, 0.31, \"Histogram, bins shifted\")\n",
    "\n",
    "# tophat KDE\n",
    "kde = KernelDensity(kernel=\"tophat\", bandwidth=0.75).fit(X)\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "ax[1, 0].fill(X_plot[:, 0], np.exp(log_dens), fc=\"#AAAAFF\")\n",
    "ax[1, 0].text(-3.5, 0.31, \"Tophat Kernel Density\")\n",
    "\n",
    "# Gaussian KDE\n",
    "kde = KernelDensity(kernel=\"gaussian\", bandwidth=0.75).fit(X)\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "ax[1, 1].fill(X_plot[:, 0], np.exp(log_dens), fc=\"#AAAAFF\")\n",
    "ax[1, 1].text(-3.5, 0.31, \"Gaussian Kernel Density\")\n",
    "\n",
    "for axi in ax.ravel():\n",
    "    axi.plot(X[:, 0], np.full(X.shape[0], -0.01), \"+k\")\n",
    "    axi.set_xlim(-4, 9)\n",
    "    axi.set_ylim(-0.02, 0.34)\n",
    "\n",
    "for axi in ax[:, 0]:\n",
    "    axi.set_ylabel(\"Normalized Density\")\n",
    "\n",
    "for axi in ax[1, :]:\n",
    "    axi.set_xlabel(\"x\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Plot all available kernels\n",
    "X_plot = np.linspace(-6, 6, 1000)[:, None]\n",
    "X_src = np.zeros((1, 1))\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(left=0.05, right=0.95, hspace=0.05, wspace=0.05)\n",
    "\n",
    "\n",
    "def format_func(x, loc):\n",
    "    if x == 0:\n",
    "        return \"0\"\n",
    "    elif x == 1:\n",
    "        return \"h\"\n",
    "    elif x == -1:\n",
    "        return \"-h\"\n",
    "    else:\n",
    "        return \"%ih\" % x\n",
    "\n",
    "\n",
    "for i, kernel in enumerate(\n",
    "    [\"gaussian\", \"tophat\", \"epanechnikov\", \"exponential\", \"linear\", \"cosine\"]\n",
    "):\n",
    "    axi = ax.ravel()[i]\n",
    "    log_dens = KernelDensity(kernel=kernel).fit(X_src).score_samples(X_plot)\n",
    "    axi.fill(X_plot[:, 0], np.exp(log_dens), \"-k\", fc=\"#AAAAFF\")\n",
    "    axi.text(-2.6, 0.95, kernel)\n",
    "\n",
    "    axi.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    axi.xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    axi.yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "    axi.set_ylim(0, 1.05)\n",
    "    axi.set_xlim(-2.9, 2.9)\n",
    "\n",
    "ax[0, 1].set_title(\"Available Kernels\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Plot a 1D density example\n",
    "N = 100\n",
    "np.random.seed(1)\n",
    "X = np.concatenate(\n",
    "    (np.random.normal(0, 1, int(0.3 * N)), np.random.normal(5, 1, int(0.7 * N)))\n",
    ")[:, np.newaxis]\n",
    "\n",
    "X_plot = np.linspace(-5, 10, 1000)[:, np.newaxis]\n",
    "\n",
    "true_dens = 0.3 * norm(0, 1).pdf(X_plot[:, 0]) + 0.7 * norm(5, 1).pdf(X_plot[:, 0])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.fill(X_plot[:, 0], true_dens, fc=\"black\", alpha=0.2, label=\"input distribution\")\n",
    "colors = [\"navy\", \"cornflowerblue\", \"darkorange\"]\n",
    "kernels = [\"gaussian\", \"tophat\", \"epanechnikov\"]\n",
    "lw = 2\n",
    "\n",
    "for color, kernel in zip(colors, kernels):\n",
    "    kde = KernelDensity(kernel=kernel, bandwidth=0.5).fit(X)\n",
    "    log_dens = kde.score_samples(X_plot)\n",
    "    ax.plot(\n",
    "        X_plot[:, 0],\n",
    "        np.exp(log_dens),\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        linestyle=\"-\",\n",
    "        label=\"kernel = '{0}'\".format(kernel),\n",
    "    )\n",
    "\n",
    "ax.text(6, 0.38, \"N={0} points\".format(N))\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.plot(X[:, 0], -0.005 - 0.01 * np.random.random(X.shape[0]), \"+k\")\n",
    "\n",
    "ax.set_xlim(-4, 9)\n",
    "ax.set_ylim(-0.02, 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02efdf95-6b91-4152-93ce-c4e8530376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X\n",
    "X_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93e3a6-ada1-45c2-b498-79ec66b3fc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
